---- Page 1 ----
Computers and Education: Artificial Intelligence 3 (2022) 100042
Available online 3 December 2021
2666-920X/© 2021 The Author(s). Published by Elsevier Ltd. This is an open access article under the CC BY-NC-ND license ( http://creativecommons.org/licenses/by-
nc-nd/4.0/ ).Domain-specific NLP system to support learning path and curriculum 
design at tech universities 
Nhi N.Y. Voa,*, Quang T. Vua, Nam H. Vua, Tu A. Vua, Bang D. Macha, Guandong Xub 
aRMIT University Vietnam, 702 Nguyen Van Linh Boulevard, District 7, Ho Chi Minh City, 70000, Viet Nam 
bUniversity of Technology Sydney, 15 Broadway, Ultimo, 2007, NSW, Australia   
ARTICLE INFO  
Keywords: 
Data science applications in education 
Architectures for educational technology 
system 
Teaching/learning strategies ABSTRACT  
The tech sector has been growing at a rapid speed, demanding a higher level of expertise from its labor force. 
New skills and programming languages are introduced and required by the industry every day, while the uni-
versity courses are not updated adequately. Finding the high-demand skills and relevant courses to study has 
become essential to both students and faculty members at tech universities, which leads to a growing research 
interest in building an intelligence system to support decision making. Leveraging recent development in Natural 
Language Processing, we built an NLP-based course recommendation system specifically for the computer sci-
ence (CS) and information technology (IT) fields. In particular, we built (1) a Named Entity Recognition (CSIT- 
NER) model to extract tech-related skills and entities, then used these skills to build (2) a personalized multi-level 
course recommendation system using a hybrid model (hybrid CSIT-CRS). Our CSIT-NER model, trained and fine- 
tuned on a large corpus of text extracted from StackOverflow and GitHub, can accurately extract the relevant 
skills and entities, outperforming state-of-the-art models across all evaluation metrics. Our hybrid CSIT-CRS can 
provide recommendations on multiple individualized levels of university courses, career paths with job listings, 
and industry-required with suitable online courses. The whole system received good ratings and feedback from 
users from our survey with 201 volunteers who are students and faculty members of tech universities in Australia 
and Vietnam. This research is beneficial to students, faculty members, universities in CS/IT higher education 
sector, and stakeholders in tech-related industries.   
1.Introduction 
In recent years, Computer Science (CS) and Information Technology 
(IT) fields have been evolving rapidly. With new programming lan-
guages, frameworks, tools, and systems coming out every month, the 
tech companies begin to demand new skills and knowledge when 
recruiting for specific technical roles. It becomes harder for universities 
to keep track of all the latest technologies required by the industry. 
Besides, along with the booming of e-learning technology and services, 
there are countless Massive Open Online Courses (MOOCs) available for 
free on different platforms, e.g. Coursera, EdX, etc. Some of these 
MOOCs are taught by professionals working at big tech companies, so 
the materials are often updated and are closer to the industry standard. 
The movement to online and remote learning with cost-effective micro 
degrees has made traditional and expensive CS/IT programs outdated 
(Prates, Garcia, & Maldonado, 2018 ). As a result, the performance gap 
between skills taught at universities and those required by the companies is widened (Oguz & Oguz, 2019 ). Many approaches are being 
investigated to close this gap (Garousi, Giray, Tuzun, Catal, & Felderer, 
2020 ; Valstar, 2019 ). There has been a lack of intelligence systems to 
support student learning and curriculum design at CS/IT programs 
offered at universities. 
On the other hand, advanced text mining techniques have been 
applied to solve Natural Language Processing (NLP) problems in other 
areas, especially using the Named Entity Recognition (NER) task (Saju & 
Shaja, 2017 ). There is an increasing interest in applying NER models for 
keyword extraction in CS/IT field (Tabassum, Maddela, Xu, & Ritter, 
2020 ; Ye et al., 2016 ). Initial studies on building an in-domain NLP 
system at tech universities have also been investigated by Ma, Wang, 
Hou, and Lu (2017) ; Pardos and Jiang (2020) . However, the current 
literature has either stopped at a theoretical model or a simple system 
without any real-world benefits to the students or the universities. 
Realizing this research gap, we conduct this research building an 
NLP-based course recommendation system to address the below 
*Corresponding author. 
E-mail address: nhi.vongocyen@rmit.edu.vn (N.N.Y. Vo).  
Contents lists available at ScienceDirect 
Computers and Education: Artificial Intelligence 
u{�~zkw! s{yo|kr o>!ÐÐÐ1�mt ozmont~om�1 m{y2u{�~zk w2m{y|��o~�/k zn/on�mk�t {z/k~�tˆmtkw /tz�owwtrozmo!
https://doi.org/10.1016/j.caeai.2021.100042 
Received 29 September 2021; Received in revised form 27 November 2021; Accepted 28 November 2021   

---- Page 2 ----
Computers and Education: Artificial Intelligence 3 (2022) 100042
2research questions:  
Q1 What skills/knowledge are still missing in these university 
programs?  
Q2 Which future career can a student take with the current learning 
path?  
Q3 Which courses should a student take to prepare for a specific tech 
career? 
The research focuses on building an intelligence system to improve 
the quality of CS/IT programs at tech universities based on advanced 
text mining and NLP methods. It compares the knowledge and skills 
taught in the current course offerings at these universities and the real- 
life job requirements. The NLP system supports decision-making in the 
development of these programs and the improvement of universities ’ 
life-ready teaching curriculum. This research project contributes to both 
theoretical and practical knowledge based on both information systems 
and the education domain. The paper contributes significantly to both 
the extension of the current literature and the solving of real-world 
problems in two folds. 
Theoretical contributions:  
1. Developing a novel CS/IT domain-specific named entity recognition 
model to extract keywords and analyse the CS/IT courses and jobs 
description.  
2. Being one of the first systems, according to our knowledge, to 
leverage a novel NLP model for a CS/IT course recommendation 
system based on industry requirements in higher-education 
universities. 
Societal contributions:  
1. Building a hybrid recommendation system to suggest new skills/ 
courses for different CS/IT programs, which improves the program 
quality and students ’ satisfaction.  
2. Constructing an intelligence system to assist students in choosing 
elective courses suitable for their career aspirations, which increases 
their technical capability and employability.  
3. Enhancing the learning experience and quality of students, which 
leads to increasingly higher skilled graduates joining the workforce. 
The research and the NLP course recommendation system aim to be 
beneficial to various stakeholders, e.g. CS/IT students (choosing suitable 
courses for their learning and career path), faculty members (updating 
curriculum design), universities (having better student experience and 
satisfaction), employers, and society (work-ready graduates with rele-
vant skills). 
2.Literature review 
2.1. NER models in CS/IT field 
Named Entity Recognition (NER) has recently become a popular 
topic among NLP researchers. However, most NLP systems consist of 
NER models with real-world entities only, such as organization names, 
location, event date, etc. (Goyal, Gupta, & Kumar, 2018 ). Multiple 
neural network architectures have been investigated for this task, e.g. 
the Convolutional Neural Networks (CNN), the Bidirectional Long 
Short-Term Memory Networks (BiLSTM) (Shen, Yun, Lipton, Kronrod, & 
Anandkumar, 2017 ), the Gated Convolutional Neural Networks (Wang, 
Chen, & Xu, 2017 ). Other investigated deep learning approaches 
researched are adaptive co-attention network (Zhang, Fu, Liu, & Huang, 
2018 ) and multi-task learning (Aguilar, Maharjan, L˘opez-Monroy, & 
Solorio, 2017 ) in social media data. 
Domain-specific NER is an emerging research trend, particularly in 
the CS/IT field. Little research has been carried on this specific topic, apart from some tech-related keyword extraction tools (Mendes, Jakob, 
García-Silva, & Bizer, 2011 ). Some previous models of NER in CS/IT 
fields (Ye et al., 2016 ) are based on Conditional Random Field (CRF), a 
type of statistical modeling method for pattern recognition and struc-
tured prediction (Collobert et al., 2011 ). However, with the growth of 
artificial intelligence research, more deep learning techniques have been 
applied to build more advance NER models (J. Li, Sun, Han, & Li, 2020 ). 
Huang, Wang, and Wang (2020) have combined the BiLSTM with CRF to 
detect domain-specific entities in scientific literature and enrich their 
NER model with Rapid Automatic Keyword Extraction (RAKE). A Deep 
neural network for Bug-specific NER (DBNER), introduced by Zhou, Li, 
and Sun (2020) , has combined BiLSTM and CRF to build an enhanced 
NER model in the CS/IT field. 
Regarding the embedding techniques, researchers have applied text 
mining on datasets from tech-related social media sites, particularly the 
two popular websites StackOverflow and GitHub. Using BERT (Devlin, 
Chang, Lee, & Toutanova, 2019 ) embedding methods as the base, 
multiple embedding models have been released, which enables the 
enhancement of NER models. Some of the state-of-the-art embedding 
methods are SciBert (Beltagy, Lo and Cohan, 2019 ) and BERTOverflow 
(Tabassum et al., 2020 ). We use BERTOverflow to benchmark our 
domain-specific model named CSIT-NER. 
To conclude, these research projects resulted in a strong foundation 
for solving the NLP task with NER in CS/IT field. However, the literature 
has stopped at the theoretical NLP models stage. Little work has been 
done to apply these models to solve real-world problems. Realizing this 
research gap, we aspired to build and apply a CS/IT domain-specific 
NER model for a course recommendation system that can leverage 
advanced deep learning NLP techniques. 
Moreover, transfer learning for the NER model has been recently 
investigated by Lee, Dernoncourt, and Szolovits (2018) and Tabassum 
et al. (2020) . The initial studies have shown the potential of this 
approach, which is the motivation of this paper. Our CSIT-NER model 
aims to achieve good performance compared to other state-of-the-art 
models and to be even better at transfer learning for accurately 
extracting the CS/IT entities. We can then leverage the CSIT-NER model 
for our decision support system for student learning and curriculum 
design. 
2.2. Course recommendation system for CS/IT students 
While NER is an emerging NLP research topic, the Course Recom -
mendation System (CRS) has been extensively investigated in the past 
decades (Thanh-Nhan, Nguyen, & Thai-Nghe, 2016 ). Regarding tradi-
tional approaches, Lin, Pu, Li, and Lian (2018) have applied sparse linear 
method (SLIM) to query the top-N recommended courses in Information 
Management programs at Chinese universities, and Bhumichitr, Chan -
narukul, Saejiem, Jiamthapthaksin, and Nongpong (2017) have used 
both Pearson Correlation Coefficient and Alternating Least Square (ALS) 
to suggest courses based on the similarity of their descriptions. Some 
researchers have tried to solve the problem using ontology (Huang, 
Chen, & Chen, 2013 ; Ibrahim, Yang, Ndzi, Yang, & Al-Maliki, 2019 ), 
while Mondal, Patra, Mishra, and Patra (2020) have used the k-means 
clustering algorithm to build a grade-based CRS. 
Different recommendation system approaches such as collaborative 
filtering have been studied by Hui, Jun, Zhang, and Yun (2017) to 
improve the CRS. Due to the popularity and data availability, there are 
more research works on recommendation systems for MOOCs than 
traditional university ones Xiao, Wang, Jiang, and Li (2018) ; De Medio, 
Limongelli, Sciarrone, and Temperini (2020) . However, most of these 
CRS is not constructed specifically for any domain, especially CS/IT 
programs, which is the research interest of this paper. 
Regarding the application of NLP techniques to improve the CRS, 
some initial studies have been carried out in recent years (Rao et al., 
2019 ). Simple Word2Vec pipeline has been used for calculating se-
mantic similarity between courses (Ma et al., 2017 ). Pardos and Jiang N.N.Y. Vo et al.                                                                                                                                                                                                                                 

---- Page 3 ----
Computers and Education: Artificial Intelligence 3 (2022) 100042
3(2020) have also implemented a Course2Vec model (based on the 
Word2Vec model) with Recurrent Neural Networks (RNN) in their CRS. 
RNN has also been the chosen network for a goal-based CRS proposed by 
Jiang, Pardos, and Wei (2019). Other NLP methods such as topic and 
sentiment analysis have been combined with survey data for a person -
alized CRS built by Ng and Linn (2017). 
While these NLP approaches have done a thorough job on the course 
description, none of them has incorporated the industry side by applying 
text mining on the job description. Their systems also focus only on 
finding similar courses, which is unrealistic as students would not want 
to learn the same topic again. Realizing this research gap, we aim to 
build a CS/IT domain-specific CRS (CSIT-CRS) that can recommend the 
courses with the new skills required by the industry and tech they have 
not learned yet. The CRS is personalized based on both their career in-
terest and their learning history, combining both the CSIT-NER model 
and collaborative filtering with other user preferences. 
3.Methodology 
Our NLP system used data from various sources. Firstly, we used 
Beautiful Soup and Selenium to scrape data from multiple websites 
which contained the job postings, course descriptions, and MOOCs on-
line courses information (see Section 3.1). Secondly, we built and fine- 
tuned the CSIT-NER model as in Section 3.2 by using the annotated 
corpus from StackOverflow and GitHub provided by Tabassum et al. 
(2020). The trained CSIT-NER was then applied to the scraped job and 
course datasets to extract relevant entities. Next, the predicted CS/IT 
skills were combined with output tokens from Emsi1 to further extend 
our list of skills. The combined skill lists had been thoroughly checked 
and updated frequently, which further enhanced our hybrid CSIT-CRS 
(see Section 3.3). Finally, we built a web application to provide user 
interaction with the three distinctive use cases as described in Section 
3.4. The full NLP System framework is as in Fig. 1. 
3.1. Automatic data scraper 
We build multiple scraping bots to automatically collect data from 
tech university courses, job listings, and MOOCs. The real-time data we 
use is susceptible to changes in the current vacancies and curriculum of 
universities. To ensure our system maintains a good level of data 
integrity and can react with the change of data sources, we take two 
aspects into considerations: (1) Framework for scraping bots to optimize 
resources and achieve high efficiency, and (2) Update frequency for each 
data source to ensure the database is up to date. 
3.1.1. Framework 
We use the Selenium and Beautiful Soup frameworks for our auto-
matic scraping bots due to their efficiency and resource optimization 
(Chaulagain, Pandey, Basnet, & Shakya, 2017). The framework applied 
to each data source is as below:  
1. Course Descriptions: The Selenium technique is used to simulate the 
login process and user behavior as some university websites require 
login to access their course guides.  
2. Job Descriptions: Beautiful Soup technique is selected as the jobs are 
public on Glassdoor2 with no restriction.  
3. MOOCs: The Beautiful Soup technique is selected as The MOOCs are 
public on Class Central3 with no restriction. 3.1.2. Update frequency 
All data sources are likely to change after a certain amount of time. 
We need to identify the sweet spot of the period to update our data to 
maintain data integrity while still optimizing resources. 
The university course information is usually updated before the ac-
ademic semester begins if there are any changes in the teaching mate-
rials. Universities often have the semester time of 18–22 weeks and 6–8 
weeks of semester break. To keep up with the latest update, we update 
the scraping bots every two months. 
The available job postings in Glassdoor change at a much faster pace 
as the industry grows quickly and tech companies are all looking out for 
talents. Each job posting often lasts for 1–3 months, depending on the 
company recruitment campaign. The scraping bot automatically updates 
weekly. 
The online courses from MOOCs data help for both personal learning 
and getting hands-on experiences. Many courses last for years and 
receive feedback for over five years. Even good quality online courses 
come out every few months, but find difficulty competing with the 
reputable ones introduced in the past. Therefore, the bot for this data 
source automatically updates monthly. 
3.2. CS/IT named entity recognition model (CSIT-NER) 
Fig. 2 summarizes an end-to-end data pipeline for our CSIT-NER 
model. First of all, we obtained datasets from StackOverflow/GitHub 
and scraped data for jobs and courses from multiple websites. We split 
the StackOverflow dataset into a train, a validation, and a test set for our 
model training and evaluation. Secondly, we pre-processed the raw texts 
by removing English stop words using the NLTK Python package (Bird, 
Klein, & Loper, 2009) and tokenized them with a pre-trained Stack -
Overflow tokenizer. We then passed the tokenized corpus through 
embedding layers using in-domain fine-tuned BertOverflow and Fasttext 
models. After the sets were embedded, we used the train and validation 
sets to build and fine-tune our NER model. The embedding vectors were 
fed into a stacked BiLSTM and Fully Connected Layers as in Fig. 3. 
Our CSIT-NER model containing 6,757,136 parameters was trained 
using Adamax optimizer with a learning rate of 0.001 and a batch size of 
128 for 50 epochs (see Section 5.1.3 for parameter tuning). All datasets 
were imbalanced as more than 90% of words were not entities, so we 
used the bias initializer based on the class weight in the last layer to help 
improve the model accuracy. We also looked into the comparison of 
models with and without class weight in Section 5.1.2. 
We then evaluated the model on the StackOverflow test set. We 
further tested our model capability of transfer learning by assessing its 
performance on the GitHub dataset. Finally, we used the final CSIT-NER 
model to extract entities on the course and job datasets and integrated 
them into our CSIT-CRS. 
3.3. CS/IT course recommendation system (CSIT-CRS) 
3.3.1. Use cases 
Our CSIT-CRS is designed to support students and academic faculty 
members at universities in multiple situations. 
For students, there are two different scenarios. The first scenario is 
when the students want to know which specific skills or courses they 
need to pursue a career path. They can enter the career options into the 
system and receive a list of most-demanded skills and tools required by 
the industry for that particular career path, together with a list of current 
courses at their university offering the previous skills and tools (Use case 
1 on the Web Application). Alternatively, they can add their study his-
tory, including all the past courses, to receive a list of additional skills 
which they still need to improve on and the links to available MOOCs to 
help them acquire those skills (Use case 3 on the Web Application). 
The second scenario is when the students are uncertain of which 
career options to follow, our system can recommend the most potential 
career paths based on their strengths and past performance. More 1Emsi is an open-source library with over 30,000 skills gathered from hun-
dreds of millions of job postings, profiles, and resumes. See https://api.emsi 
data.com/.  
2 https://www.glassdoor.com/.  
3 https://www.classcentral.com/. N.N.Y. Vo et al.                                                                                                                                                                                                                                 

---- Page 4 ----
Computers and Education: Artificial Intelligence 3 (2022) 100042
4specifically, they are interested in finding a job posted by companies that 
can match their skills and levels of expertise. The students can enter the 
courses they have taken and receive the following: a list of potential 
career paths together with a link to related job listings online so they can 
conveniently apply for those positions (Use case 2 on the Web 
Application). 
For academic faculty members, our system can help them to keep 
track of new technologies/skills from the market to keep their courses up 
to date. The lecturers or professors can enter a course or a list of their teaching courses together with a chosen field in the market. The system 
returns the following items: a list of skills/technologies from the chosen 
field which are still missing from their courses and the links to available 
online resources that can help them update or redesign their courses 
(Use case 3 on the Web Application). 
3.3.2. Hybrid CSIT-CRS model 
At the early stage, our system faced a cold start problem due to the 
lack of user interactions. Therefore, we implemented a context-aware 
Fig. 1.NLP System overview.  
Fig. 2.CSIT-NER model pipeline.  N.N.Y. Vo et al.                                                                                                                                                                                                                                 

---- Page 5 ----
Computers and Education: Artificial Intelligence 3 (2022) 100042
5RecSys using the extracted skills from the CSIT-NER models and Emsi 
API. The NLP-based model was further enhanced by a supervised 
ranking fusion method. 
First of all, we denote τi as the list of extracted entities for course i and 
τj as those for job j, i ∃{1, 2, …, I} and j ∃{1, 2, …, J}. We also have the 
context notions of the user’s chosen career path cpu and study history shu 
for user u, u ∃{1, 2, …, U}. I, J and U are the total numbers of courses, 
jobs and users respectively in our database. We initially compute a map- 
reduce function by counting the entities, ranking the order of entity 
aggregations in τi and τj then getting the top ε most popular entities for 
each list. We denote these Tε
i and Tε
i. 
After that, we can use Ti and Tj to calculate the context-aware sim-
ilarity score between course i and job j as: 
ωTε
i⊂Tε
jTε
i}Tε
j
Tε
i⊖Tε
j(1) 
On the other hand, the context-aware dissimilarity score is given by: 
ωTε
iℑ≫Tε
jTε
i〉Tε
j
Tε
i⊖Tε
j(2) 
We then can get the φ ranked top k courses by: ρε
ijkφωTε
i⊂Tε
jCk (3) 
Similarly, we have τs as the list of all the courses taken by student s, s 
∃{1, 2, …, S}. Let Tε
s be the top ε skills that student s has obtained from 
those courses, we can calculate the context-aware similarity score ω and 
get the φ ranked top k career paths and jobs by: 
ρε
jskφωTε
j⊂Tε
sCk (4) 
Lastly, the supervised ranking fusion approach combines pair-wise 
similarity and dissimilarity ranked lists to compile the final top k rec-
ommendations for each use case in our CSIT-CRS. We can calculate the 
dissimilarity score Δ to get the top l missing skills of the students, then 
compute the context-aware similarity score ω and get the φ ranked top k 
MOOCs by: 
ΔjsεlφωTε
jℑ≫Tε
sCl (5)  
ρε
mjskφωTε
m⊂ΔjsεlCk (6)  
where τm is the list of extracted entities for MOOC m, m ∃{1, 2, …, M}; 
and τε
m be the top ε extracted entities of MOOC m. 
To overcome cold-start problems, we asked volunteers to rate t 
Fig. 3.CSIT-NER neural network layers (units and activation in the brackets).  
Fig. 4.Hybrid CSIT-CRS framework.  N.N.Y. Vo et al.                                                                                                                                                                                                                                 

---- Page 6 ----
Computers and Education: Artificial Intelligence 3 (2022) 100042
6courses recommended by the context-aware RecSys. All the rated 
courses and user interaction of the content-based model will be one of 
the inputs to build our hybrid CSIT-CRS. Fig. 4 illustrates the whole 
framework of our hybrid CSIT-CRS model, where we combine both 
context-aware CSIT-CRS and collaborative filtering module with a 
Restricted Boltzmann Machine model. The hybridization layer is 
calculated as a weighted average dynamically adjusted based on the 
weight α regarding the context (cpu, shu) of each individual user u. 
rαcpuCshu
u r11 αcpuCshu
ur2 (7)  
where r1, r2, and r are the recommendation 1 (context-aware), recom -
mendation 2 (collaborative filtering), and the final recommendations of 
our hybrid CSIT-CRS model accordingly. 
3.4. Web application 
We created a web application to implement the work result (see 
Fig. 5). The front-end of the web app used ReactJS (Fedosejev, 2015 ) 
where the Material Design principle was applied as it is the current 
Google standard in web design.4 For the back-end of the application, we 
chose Flask (Grinberg, 2018 ) as it is often preferred for deploying ma-
chine learning models thanks to its easy learning curve and flexibility. 
Finally, the team used PostgreSQL (Obe & Hsu, 2017 ) as the main 
database framework for the web application. PostgreSQL is well known 
for supporting machine learning related projects by integrating exten -
sions, hence using PostgreSQL would provide easy implementation and 
scalability for our web application. To deploy the web application to the 
cloud service, the team used Amazon Web Services (AWS),5 one of the 
most popular cloud platforms which are scalable and reasonable in 
price. The AWS Relational Database Service (RDS) coming from the 
same package would be used to implement PostgreSQL instance on the 
AWS cloud services and Elastic Compute Cloud (AWS EC2) would be 
used to implement the front-end and the back-end of the web 
application. 
The web application has two defined routes for users: Common User 
and Administrator. The normal user is only able to access the User Web 
Page. The User Web Page provides an interface to the 3 use cases as 
mentioned in Section 3.3. The Admin Web Page can be accessed using a 
pre-registered Administrator account with a hashed password. The 
Admin Web Page is secured by using JSON Web Token (JWT Token) 
(Jones, Campbell, & Mortimore, 2015 ) method to reduce the number of 
authenticating username and password for each request. 
4.Datasets 
We used multiple datasets to build our whole NLP system (see 
Table 1). The named entities of the StackOverflow and GitHub datasets 
were annotated manually. The entities of the job and course description 
datasets are referring to only the skills extracted from the Emsi API. We 
combined these with the output predictions from the CSIT-NER model 
before feeding it to the CSIT-CRS. 
4.1. NER datasets 
To benchmark our CSIT-NER model, we used two public NER data-
sets in the CS/IT field, namely the annotated StackOverflow and GitHub 
NER datasets. Tabassum et al. (2020) defined 20 types of annotated 
entities, including 8 coding language entities and 12 natural language 
entities. We focused only on the 11 relevant entities in this research. The 
entities are LIBRARY, APPLICATION, UI ELEMENT, LANGUAGE, DATA 
STRUCTURE, FILE TYPE, FILE NAME, VERSION, DEVICE, OS, and WEBSITE (plus the tag O for non-entity words). 
4.2. Course description dataset 
The dataset contains titles and descriptions of the available courses 
from 10 universities in Vietnam and Australia, namely University of 
Adelaide, Australian National University, University of Melbourne, 
Monash University, University of New South Wales, University of 
Queensland, University of Sydney, University of Western Australia, 
University of Technology Sydney and RMIT University Vietnam. In total, 
we had scraped 1385 courses (updated in June 2021) from these schools. 
This dataset consists of 4 attributes: UNIVERSITY, COURSE CODE, 
COURSE NAME, and COURSE DESCRIPTION. 
4.3. Job description dataset 
The dataset was scraped from Glassdoor, including 2154 jobs 
(updated in June 2021) from 12 different SE/IT career paths in Vietnam 
and Australia. We filtered the job listings using the 12 search terms: 
Android Developer, Cyber Security, Data Engineer, Data Scientist, 
DevOps, Full Stack Developer, iOS Developer, Machine Learning, QA, 
Software Engineer, Software Developer, and Web Developer. As we use 
the automatic scraping bots, the number of jobs could vary by 15%, 
depending on the current vacancies. This dataset consists of 4 attributes: 
JOB TITLE, JOB DESCRIPTION, COMPANY NAME, and URL. 
5.Empirical results 
5.1. CSIT-NER evaluation 
5.1.1. Benchmarking results 
We benchmarked our CSIT-NER model against other baselines and 
state-of-the-art models as described by Tabassum et al. (2020) , namely 
the Feature-based Linear CRF and SoftNER. We also included two 
baseline model variations using BiLSTM with in-domain BERT (BER -
TOverflow) or Fasttext embeddings. To test the transfer learning per-
formance, we benchmarked our CSIT-NER model against a BiLSTM-CRF 
neural network trained on the GitHub dataset and the transfer learning 
from other mentioned approaches. 
We used three different evaluation metrics to evaluate our CSIT-NER 
model, namely the precision, recall, and F1 score. The calculation for 
these metrics is as follows, where TP means True Positive and FP means 
False Positive: 
PrecisionTP
TPFP(8)  
RecallTP
TPFN(9)  
F12*Precision *Recall
PrecisionRecall2*TP
2*TPFPFN(10) 
Table 2 shows the experimental results of previous works and 
different proposed architectures of the CSIT-NER model on the Stack -
Overflow validation and test sets. The CSIT-NER with character- 
sentence embedding achieved a significant improvement of 8%–10% 
in all metrics compared to the state-of-the-art SoftNER model for the 
validation set. For the test set, it outperformed other models by at least 
2%–4%. More importantly, the model with character-sentence embed -
ding had a trade-off balance between precision and recall and the 
highest F1 scores for both datasets, not suffering from high precision and 
low recall as in model BiLSTM with only BERTOverflow or Fasttext. 
Table 3 demonstrates the model transfer learning performance on 
GitHub NER datasets in comparison with other baselines. Our CSIT-NER 
with character and sentence embedding can outperform the BiLSTM- 
CRF model which was trained specifically on the GitHub dataset. 4 https://material.io/design .  
5 https://aws.amazon.com/ . N.N.Y. Vo et al.                                                                                                                                                                                                                                 

---- Page 7 ----
Computers and Education: Artificial Intelligence 3 (2022) 100042
7Moreover, our final CSIT-NER performed better than the model with 
only character embedding by 4% in the recall score. To conclude, our 
CSIT-NER model achieved great performance with both the Stack -
Overflow and GitHub datasets. Especially with the significant results in 
the GitHub dataset, we could prove the transfer learning capability of 
our CSIT-NER model, which is deemed suitable for application to the job 
and course descriptions datasets in our CSIT-CRS. 5.1.2. Imbalance learning test 
High imbalance occurred on our dataset as the tag O for non-entity 
words took up more than 90% of our dataset. Besides the bias initial -
izer mentioned in Section 3.2, we could further adjust our model by 
using the class weights calculated for each tag in the dataset. To inves -
tigate the effect of this method, we compared our CSIT-NER model with 
and without class weight adjustment in Table 4. 
From the imbalance learning test, it can be observed that adding 
class weight did not affect the F1 score by any significant margin. It 
increased the recall metrics by trading off with lower precision scores. 
Our CSIT-NER model without class weight had high precision and low 
recall. This happens when the model returns only a few tags and most of 
them are correct, but the model misses many tags for programming 
fields. Meanwhile, the model using only bias initializer still achieved the 
maximized F1 score, which proved that it is robust against changes in 
imbalance learning methods. Therefore, we keep the CSIT-NER model 
without class weight as our final model. 
5.1.3. Hyper-parameters tuning 
Training batch size and optimizer learning rate are two hyper -
parameters that can affect the overall performance of the model. 
Therefore, we want to test the robustness of our model against variations 
of these two hyperparameters. 
Fig. 6 reports the CSIT-NER test performance when changing 
different values of batch size, e.g. 32, 64, 128, and 256, measured by the 
F1 score on the validation set. For the first 3 models with batch size 
values of 32, 64, and 128, the F1 scores on the validation set were almost 
identical after 46 epochs. There was a slight decrease in the validation 
F1 score when the batch size was increased to 256. The differences were 
less than 0.5% at 50 epochs. 
Fig. 7 provides the same experiences for our CSIT-NER model with 
the learning rate in the range from 0.05 to 0.0005. The first model with a 
0.05 learning rate could reach 71% on validation f1 score. When the 
learning rate was decreased to 0.01, the F1 score reflected a small 
Fig. 5.Web application architecture.  
Table 1 
Overview of all datasets.  
Dataset #docs #sentences #tokens #entities 
StackOverflow train 1638 9263 78,329 6422 
StackOverflow val 536 2936 24,937 2268 
StackOverflow test 564 3108 26,324 2272 
GitHub 143 8023 50,447 4095 
Job description 2154 30,293 1,085,731 2907 
Course description 1385 9399 270,543 1886  
Table 2 
CSIT-NER model performance on StackOverflow NER dataset.  
Dataset Model Precision Recall F1 
Val set Feature-based CRF 0.694 5 0.471 3 0.567 4 
SoftNER 0.705 8 0.646 2 0.668 3 
BiLSTM (BERTOverflow) 0.737 3 0.593 5 0.629 3 
BiLSTM (Fasttext) 0.734 0 0.637 8 0.673 9 
CSIT-NER (char-emb) 0.730 2 0.670 6 0.691 5 
CSIT-NER (char-sent-emb) 0.805 4 0.727 0 0.761 8 
Test set Feature-based CRF 0.728 7 0.399 6 0.546 2 
SoftNER 0.764 6 0.687 3 0.718 3 
BiLSTM (BERTOverflow) 0.763 0 0.605 9 0.634 5 
BiLSTM (Fasttext) 0.770 0 0.638 9 0.690 3 
CSIT-NER (char-emb) 0.783 3 0.693 4 0.730 2 
CSIT-NER (char-sent-emb) 0.770 8 0.728 8 0.744 2  
Table 3 
CSIT-NER model transfer learning performance on GitHub NER dataset.  
Model Precision Recall F1 
BiLSTM-CRF (trained on GitHub) 0.645 3 0.609 6 0.626 9 
Feature-based CRF 0.451 3 0.376 1 0.397 8 
SoftNER 0.613 2 0.606 6 0.605 5 
BiLSTM (BERTOverflow) 0.633 0 0.586 8 0.588 3 
BiLSTM (Fasttext) 0.618 0 0.587 0 0.594 5 
CSIT-NER (char-emb) 0.638 6 0.645 1 0.632 6 
CSIT-NER (char-sent-emb) 0.649 1 0.695 4 0.644 7  
Table 4 
Imbalance learning test.  
Dataset Model Precision Recall F1 
Val set CSIT-NER 0.805 4 0.727 0 0.761 8 
CSIT-NER (class weight) 0.763 6 0.751 3 0.753 9 
Test set CSIT-NER 0.770 8 0.728 8 0.744 2 
CSIT-NER (class weight) 0.741 5 0.750 4 0.742 0 
GitHub set CSIT-NER 0.649 1 0.666 4 0.653 9 
CSIT-NER (class weight) 0.611 5 0.695 4 0.644 7  N.N.Y. Vo et al.                                                                                                                                                                                                                                 

---- Page 8 ----
Computers and Education: Artificial Intelligence 3 (2022) 100042
8improvement, which was approximately 1%. The pattern continued as 
the learning rate was reduced further to 0.001 when the F1 score was 
slowly improved and reached 74%. However, further decreasing the 
learning rate to 0.0005 and 0.0001 reversed the process of model per-
formance improvement. The f1 score of this model is the same as the first 
model with a 0.05 learning rate. Therefore, changing the learning rate 
from 0.05 to 0.0005 for the model reflects minor change, which made 
the f1 score vary in the range of 3–4%. 
All models have been trained on a desktop machine with an Intel i3 
10,100 processor, an NVIDIA RTX 3060 12GiB GPU, and 32GiB RAM 
running Ubuntu 10.84. The average training time of our models varied 
depending on the batch size as in Fig. 8. Overall, variations of batch size 
and learning rate hyperparameters did alter the model results, but the 
changes were insignificant in terms of model accuracy and computing 
efficiency. Our CSIT-NER model still achieved a sufficient level of ac-
curacy within a reasonable training time. Therefore, we can conclude 
that our model is robust against the parameter tuning effect. 
5.2. CSIT-CRS evaluation 
5.2.1. Context-aware RecSys results 
Volunteers had rated the courses in the ranked order for the top 15 
recommendations. We quantified the context-aware CSIT-CRS perfor -
mance by the three ranking evaluation metrics measured at the top k (k 
5,10,15), namely the Mean Reciprocal Rank (MRR) (Voorhees et al., 
2005 ), the Mean R-Precision (MRP) Schütze, Manning, and Raghavan 
(2008) , and the Mean Average Precision (MAP) (Zhu, 2004 ). We benchmarked our model in Table 5 against two common approaches in 
content-based RecSys: (1) similarity ranking with extracted skill and (2) 
similarity ranking with TF-IDF word vectors (Salton & McGill, 1986 ). 
Our NLP-based RecSys received good feedback from the users and 
significantly outperformed the two baselines by 8%–20%. This proved 
that our supervised ranking fusion approach was better than the tradi-
tional similarity ranking method. The CSIT-NER model also helped 
improve the performance significantly compared to the other common 
NLP approach using TF-IDF. The volunteers also rated our model on use 
cases 2 and 3 as in Table 6. 
5.2.2. Hybrid CSIT-CRS results 
To benchmark our hybrid CSIT-CRS method, we built two baselines 
with popular collaborative filtering models, namely the Bayesian 
Personalized Ranking Matrix Factorization (BPRMF) (Rendle, Freu-
denthaler, Gantner, & Schmidt-Thieme, 2009 ) and the Restricted 
Boltzmann Machine (RBM) (Salakhutdinov, Mnih and Hinton, 2007 ). 
For BPRMF, we set the number of factors to 200, the learning rate to 
0.01, lambda regularization to 0.001, and train for 100 iterations. For 
RBM, we set the hidden units to 600 and batch size to 60, then train for 
100 epochs. We reported the performances evaluated using a 5-fold 
cross-validation strategy with three ranking metrics Recall@k, 
NDCG@k, and MAP@k with k 5,10,15 (Valcarce, Bellogín, Parapar, & 
Castells, 2020 ). 
From Table 7, we can see that our hybrid CSIT-CRS outperforms both 
baselines on almost all the metrics for k 5,10,15. Particularly, we 
believe our context-aware model with CSIT-NER and supervised ranking 
fusion method has pushed the preferred courses higher in the recom -
mended list, leading to an increase of 3%–5% in NDCG@k and MAP@k. 
The BPRMF performance is significantly bad but slightly improved with 
k 15. This might be mainly due to the small number of users in our 
case. We can conclude that our hybrid CSIT-CRS is suitable for solving 
our cold-start problem. 
Fig. 6.Parameter tuning with batch size.  
Fig. 7.Parameter tuning with learning rate.  
Fig. 8.Average training time per epoch with different batch sizes.  
Table 5 
CSIT-CRS use case 1 results.   
Model MRR@k MRP@k MAP@k 
k 5 Baseline 1 0.727 1 0.727 1 0.723 6 
Baseline 2 0.728 1 0.604 9 0.665 6 
CSIT-CRS 0.901 2 0.799 2 0.850 1 
k 10 Baseline 1 0.730 6 0.701 5 0.719 0 
Baseline 2 0.736 4 0.550 8 0.617 7 
CSIT-CRS 0.904 2 0.733 4 0.808 1 
k 15 Baseline 1 0.730 5 0.640 1 0.697 6 
Baseline 2 0.737 9 0.519 7 0.584 3 
CSIT-CRS 0.904 2 0.699 9 0.786 7  N.N.Y. Vo et al.                                                                                                                                                                                                                                 

---- Page 9 ----
Computers and Education: Artificial Intelligence 3 (2022) 100042
96.User survey and analysis 
Finally, to evaluate the whole system from the user point of view, we 
conducted a user survey to collect their opinions in order to further 
improve the system. The user survey is divided into 3 sections: CSIT-CRS 
rating, UI/UX, and demographic questions. In the first and most 
important section of the survey, the CSIT-CRS rating is used to evaluate 
the participant regarding the relevancy and accuracy of the recom -
mendation system via the three use cases. 
The second section of the survey is the user rating for the UI/UX 
aspects of the web application. The questions consist of six questions in 
5-level Likert-type scale to measure the satisfaction of the web appli -
cation to the user:  
Q1 How easy is it to navigate through the system?  
Q2 How fast were the responses?  
Q3 How easy to use do you think of the system?  
Q4 What do you think of the system ’s design?  
Q5 How likely will you use the system to help with the study plan/ 
course design?  
Q6 How likely are you going to recommend the system to your peers? 
The last section of the survey collects user demographics to group participants accordingly. The first question asks whether the participant 
is a student or faculty member. If they are a student, the second question 
asks for their school year in university. Otherwise, it asks for their cur-
rent position in the university. The final question is optional, asking for 
their general opinion about the system in form of short written feedback. 
We collected 201 responses in total, of which 171 volunteers are 
students. There are 31 people in Year 1, 43 in Year 2, 57 in Year 3, 32 in 
Year 4, and 8 in Year 5 or above. The rest are 30 responses from faculty 
members from five different roles in their universities. We are interested 
in the preferences of our survey respondents based on either their chosen 
career paths or their demographic groups. As illustrated in Fig. 9, the 
career aspirations distribution is relatively equal among all the volun -
teers for the twelve options, with a slight surge of interest in some 
trending careers such as Data Scientist and Machine Learning. This 
further validates the CSIT-CRS rating Tables 5 and 6, showing that the 
volunteers got a varied range of personalized recommendations. 
The results in Table 8 show that respondents are satisfied with our 
system in general. The scores range from 3.3860 (Year 3 - Q4) to 4.4333 
(Staff - Q3). Questions 2 and 4, which measure our system response time 
and design, receive slightly lower scores than other questions. We will 
focus on improving these two aspects when we fully integrate our NLP 
system into the university network. 
To validate our CSIT-CRS ratings and the survey data, we performed 
three different sets of statistical hypothesis tests. First of all, we con-
ducted a quick Normality test using the Shapiro-Wilk (Shapiro & Wilk, 
1965 ). Our data did not follow Gaussian distribution at a 99% confi -
dence level (p-valueD0.01). Therefore, we decided to use 
non-parametric tests in the next step. 
In the second set, we used the Kruskal-Wallis H Test (Kruskal & 
Wallis, 1952 ) and Friedman Test (Friedman, 1937 ) to compare the data 
between different groups of survey volunteers. We split the groups in 
two ways: (A) by expert level (6 groups: students in year 1, year 2, year 
3, year 4, year 5 or above, and faculty members), and (B) by career path Table 6 
CSIT-CRS rating use case 2 and 3 results.   
k MRR@k MRP@k MAP@k 
Use case 2 - level 1 5 0.889 6 0.817 0 0.847 9 
Use case 2 - level 2 5 0.782 8 0.733 2 0.755 0 
Use case 3 - level 1 5 0.844 2 0.791 0 0.808 3 
Use case 3 - level 2 5 0.680 8 0.639 0 0.655 9  
Table 7 
Hybrid CSIT-CRS results.   
Model Recall@k NDCG@k MAP@k 
k 5 BPRMF 0.476 5 0.387 0 0.310 3 
RBM 0.982 1 0.832 3 0.760 4 
Hybrid CSIT-CRS 0.975 2 0.860 5 0.811 2 
k 10 BPRMF 0.640 7 0.449 0 0.345 4 
RBM 0.982 0 0.832 3 0.760 4 
Hybrid CSIT-CRS 0.987 2 0.865 5 0.814 9 
k 15 BPRMF 0.771 9 0.490 7 0.362 7 
RBM 0.978 2 0.839 0 0.769 4 
Hybrid CSIT-CRS 0.987 2 0.865 5 0.814 9  
Fig. 9.Career choices distribution.  Table 8 
Average UI/UX scores by group.  
Group Q1 Q2 Q3 Q4 Q5 Q6 
Year 1 4.322 6 3.548 4 4.193 5 3.709 7 4.129 0 4.129 0 
Year 2 4.162 8 3.441 9 3.860 5 3.418 6 4.046 5 4.093 0 
Year 3 4.228 1 3.526 3 3.877 2 3.386 0 4.000 0 3.789 5 
Year 4 4.250 0 3.562 5 4.218 8 3.406 3 4.218 8 4.156 3 
Year 5 or 
above 3.500 0 3.500 0 3.875 0 3.375 0 4.000 0 4.250 0 
Staff 4.300 0 4.033 3 4.433 3 3.733 3 4.233 3 4.066 7  N.N.Y. Vo et al.                                                                                                                                                                                                                                 

---- Page 10 ----
Computers and Education: Artificial Intelligence 3 (2022) 100042
10(12 groups for 12 chosen career paths). We performed the tests for the 
combined CSIT-CRS ratings and UI/UX questions first and separated the 
two sections later. H0 is that the different groups have similar ratings 
and answers, while H1 is the opposite. The result in Table 9 shows that 
we can reject H0 and accept H1 for most tests at a 99% confidence level. 
Finally, as we could not reject H0 in the Kruskal-Wallis H Test for UI/ 
UX, we conducted a pair-wise Turkey ’s HSD test (Tukey, 1949 ) at a 95% 
confidence level to compare between students and faculty members for 
all 6 UI/UX questions. The H0 and H1 are similar as before. The results 
in Table 10 further confirm the reported values in Table 8. There are 
statistical differences in the answers of Q2 and Q3 among the 2 groups, 
but not for the other questions. 
To conclude, all of the statistical hypothesis tests prove that different 
groups of survey respondents have different opinions and our reported 
results are statistically significant. 
7.Discussion 
From the empirical results, we can confirm that our NLP approach 
has a significant enhancement and contribution to personalized 
recommendation systems in CS/IT field. The CSIT-NER model achieves 
great results, which lays a strong foundation for potential breakthroughs 
in this research direction, combining domain expertise and advanced 
neural network architectures. The hybrid CSIT-CRS, on the other hand, 
has answered all three research questions we set out when building this 
NLP system. Research question 1 has been answered by use case 3 where 
all the missing skills are listed and used for MOOCs recommendation. 
Use case 2 provides the answer for research question 2 with an extension 
of links to jobs for students to apply to. The most important research 
question 3 has been answered by both use case 1 and use case 3 where 
university courses and MOOCs are suggested based on individual pref-
erences. The survey results and exhaustive tests have further confirmed 
the contribution of this paper to both current literature and society. The whole system shows the social impact sides of these theoretical 
methods by providing effective and efficient methods that can serve 
multiple stakeholders. The NLP system benefits people in not only 
higher education sectors but also the tech industry in general. Students 
can find missing skills and courses to support the pursuit of their chosen 
career path. The academic faculty members can expand their knowledge 
based on the industry-required skills and update the courses using sug-
gested online materials. Universities can leverage this to improve the 
student experience and attract more enrollments with better curriculum 
design. Companies and the industry are indirectly benefiting from this 
by recruiting graduates with more relevant skills. 
As the transfer learning capability of our model has been proven, we 
can efficiently generalize the CSIT-NER model and scale the hybrid 
CSIT-CRS to support universities from different countries, not only 
Australia and Vietnam. Furthermore, cross-domain applications can be 
investigated in the future where we apply the same approach to the 
higher education sector in other fields, such as finance or marketing. 
Last but not least, our approaches can be expanded to various systems 
and applications outside of universities, e.g. using our CSIT-NER model 
for tech recruitment or implementing our personalized hybrid CSIT-CRS 
for internal training and up-skill programs at tech companies. 
8.Conclusion 
In this research, we have investigated the named entity recognition 
task specifically for CS and IT fields. We developed an in-domain CSIT- 
NER model based on a corpus of 15,372 sentences from StackOverflow 
and 6510 sentences from GitHub. The model is one of the very first to 
investigate NER tasks for tech-related fields, outperforms state-of-the-art 
models, and is shown to be a promising benchmark for related future 
works. In addition, we developed an NLP-based hybrid CSIT-CRS for 
universities by applying the CSIT-NER model on datasets scraped from 
online course descriptions, job postings, and MOOCs platforms. The 
evaluation metrics and statistical results show that the system receives 
relatively high satisfaction among volunteers. Our system, with a strong 
societal benefit to the higher-tech education sector, is also a prospective 
candidate for implementation in multiple universities and transfer 
learning to other majors of studies or different applications in the future. 
Statements on open data and ethics 
The participants were protected by hiding their personal information 
in this study. They were voluntary and they knew that they could 
withdraw from the experiment at any time. The data can be provided 
upon requests by sending e-mails to the corresponding author. 
Declaration of competing interest 
The authors declare that they have no known competing financial 
interests or personal relationships that could have appeared to influence 
the work reported in this paper. 
Acknowledgements 
This study is supported by the 2021 RMIT Vietnam Internal Grant 
number 6 and the Capstone Project 2021.  
A.Web application User Interface 
This appendix presents the User Interface of our Web Application, including the three use cases and three visualisation dashboards on the Admin 
portal (see Fig. 10). Table 9 
Kruskal-Wallis H Test and Friedman Test results.    
Kruskal-Wallis H Test Friedman Test 
Group split t-value p-value t-value p-value 
Combined A 66.075 6 D0B0001a  113.491 3 D0B0001a  
B 154.913 5 D0B0001a  216.193 0 D0B0001a  
CSIT-CRS A 83.144 0 D0B0001a  122.771 1 D0B0001a  
B 195.931 6 D0B0001a  249.067 3 D0B0001a  
UI/UX A 6.587 5 0.253 1 15.956 9 0.006 9a 
B 14.401 9 0.211 5 32.192 1 0.000 7a  
aDenotes statistical significant at both 95% and 99% confidence levels. 
Table 10 
Turkey ’s HSD Test results.  
UI/UX Question meandiff p-value lower upper reject 
Q1  0.101 2 0.581 4  0.455 0 0.252 7 False 
Q2  0.518 7 0.010 3a  0.913 6  0.123 8 True 
Q3  0.439 2 0.013 7a  0.787 4  0.091 0 True 
Q4  0.277 2 0.140 6  0.646 7 0.092 3 False 
Q5  0.157 3 0.356 9  0.493 2 0.178 6 False 
Q6  0.049 1 0.786 9  0.393 4 0.295 2 False  
aDenotes statistical significant at 95% confidence level. N.N.Y. Vo et al.                                                                                                                                                                                                                                 

---- Page 11 ----
Computers and Education: Artificial Intelligence 3 (2022) 100042
11
Fig. 10.Web application UI.  
References 
Aguilar, G., Maharjan, S., L˘opez-Monroy, A. P., & Solorio, T. (2017). A multi-task 
approach for named entity recognition in social media data. In Proceedings of the 3rd 
workshop on noisy user-generated text (pp. 148–153). 
Beltagy, I., Lo, K., & Cohan, A. (2019). SciBERT: A pretrained language model for 
scientific text. In Proceedings of the 2019 conference on empirical methods in natural 
language processing and the 9th International joint conference on natural language 
processing (pp. 3606 –3611). EMNLP-IJCNLP) .  
Bhumichitr, K., Channarukul, S., Saejiem, N., Jiamthapthaksin, R., & Nongpong, K. 
(2017). Recommender Systems for university elective course recommendation. In 
2017 14th International joint conference on computer science and software engineering 
(pp. 1–5). JCSSE) .  
Bird, S., Klein, E., & Loper, E. (2009). Natural language processing with Python: Analyzing 
text with the natural language toolkit . O’Reilly .  
Chaulagain, R. S., Pandey, S., Basnet, S. R., & Shakya, S. (2017). Cloud-based web 
scraping for big data applications. In 2017 IEEE International conference on smart 
cloud (Smart Cloud) (pp. 138–143). IEEE.  
Collobert, R., Weston, J., Bottou, L., Karlen, M., Kavukcuoglu, K., & Kuksa, P. (2011). 
Natural language processing (almost) from scratch. Journal of Machine Learning 
Research, 12, 2493 –2537 . 
De Medio, C., Limongelli, C., Sciarrone, F., & Temperini, M. (2020). MoodleREC: A 
recommendation system for creating courses using the moodle e-learning platform. 
Computers in Human Behavior, 104, 106168 . 
Devlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2019). BERT: Pre-training of deep 
bidirectional transformers for language understanding. In Proceedings of the 2019 
conference of the North American chapter of the association for computational linguistics: Human language technologies, Volume 1 (Long and short papers) (pp. 4171 –4186). 
Minneapolis, Minnesota: Association for Computational Linguistics .  
Fedosejev, A. (2015). React.js essentials . Packt Publishing Ltd.  
Friedman, M. (1937). The use of ranks to avoid the assumption of normality implicit in 
the analysis of variance. Journal of the American Statistical Association, 32, 675–701. 
Garousi, V., Giray, G., Tuzun, E., Catal, C., & Felderer, M. (2020). Closing the gap 
between software engineering education and industrial needs. IEEE Software, 37, 
68–77. 
Goyal, A., Gupta, V., & Kumar, M. (2018). Recent named entity recognition and 
classification techniques: A systematic review. Computer Science Review, 29, 21–43. 
Grinberg, M. (2018). Flask web development: Developing web applications with Python . 
O’Reilly .  
Huang, C. Y., Chen, R. C., & Chen, L. S. (2013). Course-recommendation system based on 
ontology. In 2013 International conference on machine learning and cybernetics (pp. 
1168 –1173) . 
Huang, H., Wang, X., & Wang, H. (2020). NER-RAKE: An improved rapid automatic 
keyword extraction method for scientific literatures based on named entity 
recognition. Proceedings of the Association for Information Science and Technology, 57, 
e374. 
Hui, L., Jun, S., Zhang, S., & Yun, H. (2017). Implementation of intelligent 
recommendation system for learning resources. In 2017 12th International conference 
on computer science and education (pp. 139–144). ICCSE) .  
Ibrahim, M. E., Yang, Y., Ndzi, D. L., Yang, G., & Al-Maliki, M. (2019). Ontology-based 
personalized course recommendation framework. IEEE Access, 7, 5180 –5199 . 
Jiang, W., Pardos, Z. A., & Wei, Q. (2019). Goal-based course recommendation. In 
Proceedings of the 9th International conference on learning analytics & knowledge (pp. 
36–45). New York, NY, USA: Association for Computing Machinery .  N.N.Y. Vo et al.                                                                                                                                                                                                                                 

---- Page 12 ----
Computers and Education: Artificial Intelligence 3 (2022) 100042
12Jones, M., Campbell, B., & Mortimore, C. (2015). JSON Web Token (JWT) profile for 
OAuth 2.0 client authentication and authorization Grants. May-2015.{Online}. 
Kruskal, W. H., & Wallis, W. A. (1952). Use of ranks in one-criterion variance analysis. 
Journal of the American Statistical Association, 47, 583–621. 
Lee, J. Y., Dernoncourt, F., & Szolovits, P. (2018). Transfer learning for named-entity 
recognition with neural networks. In Proceedings of the eleventh International 
conference on language resources and evaluation (pp. 4470–4473). LREC 2018.  
Lin, J., Pu, H., Li, Y., & Lian, J. (2018). Intelligent recommendation system for course 
selection in smart education. Procedia Computer Science, 129, 449–453. 
Li, J., Sun, A., Han, J., & Li, C. (2020). A survey on deep learning for named entity 
recognition. IEEE Transactions on Knowledge and Data Engineering, 1, 1. 
Ma, H., Wang, X., Hou, J., & Lu, Y. (2017). Course recommendation based on semantic 
similarity analysis. In 2017 3rd IEEE International conference on control science and 
systems engineering (pp. 638–641). ICCSSE).  
Mendes, P. N., Jakob, M., García-Silva, A., & Bizer, C. (2011). DBpedia spotlight: 
Shedding light on the web of documents. In Proceedings of the 7th International 
conference on semantic systems (pp. 1–8). New York, NY, USA: Association for 
Computing Machinery.  
Mondal, B., Patra, O., Mishra, S., & Patra, P. (2020). A course recommendation system 
based on grades. In 2020 International conference on computer science, engineering and 
applications (pp. 1–5). ICCSEA).  
Ng, Y. K., & Linn, J. (2017). Crsrecs: A personalized course recommendation system for 
college students. In 2017 8th International conference on information, intelligence, 
systems applications (pp. 1–6). IISA).  
Obe, R. O., & Hsu, L. S. (2017). PostgreSQL: Up and running: A practical guide to the 
advanced open source database. O’Reilly.  
Oguz, D., & Oguz, K. (2019). Perspectives on the gap between the software industry and 
the software engineering education. IEEE Access, 7, 117527–117543. 
Pardos, Z. A., & Jiang, W. (2020). Designing for Serendipity in a university course 
recommendation system. In Proceedings of the tenth International conference on 
learning analytics & knowledge (pp. 350–359). New York, NY, USA: Association for 
Computing Machinery.  
Prates, J. M., Garcia, R. E., & Maldonado, J. C. (2018). MOOCs on the context of software 
engineering teaching and training: Trends and challenges. In 2018 IEEE frontiers in 
education conference (pp. 1–9). FIE).  
Rao, S., Salomatin, K., Polatkan, G., Joshi, M., Chaudhari, S., Tcheprasov, V., et al. 
(2019). Learning to be relevant: Evolution of a course recommendation system. In 
Proceedings of the 28th ACM International conference on information and knowledge 
management (pp. 2625–2633). New York, NY, USA: Association for Computing 
Machinery.  
Rendle, S., Freudenthaler, C., Gantner, Z., & Schmidt-Thieme, L. (2009). BPR: Bayesian 
personalized ranking from implicit feedback. In Proceedings of the twenty-fifth 
conference on uncertainty in artificial intelligence (pp. 452–461). 
Saju, C. J., & Shaja, A. S. (2017). A survey on efficient extraction of named entities from 
new domains using big data analytics. In 2017 second International conference on 
recent trends and challenges in computational models (ICRTCCM) (pp. 170–175). Salakhutdinov, R., Mnih, A., & Hinton, G. (2007). Restricted Boltzmann machines for 
collaborative filtering. In Proceedings of the 24th international conference on Machine 
learning (pp. 791–798). 
Salton, G., & McGill, M. J. (1986). Introduction to modern information retrieval. McGraw- 
Hill, Inc.  
Schütze, H., Manning, C. D., & Raghavan, P. (2008). Introduction to information retrieval 
(Vol. 39). Cambridge: Cambridge University Press.  
Shapiro, S. S., & Wilk, M. B. (1965). An analysis of variance test for normality (complete 
samples). Biometrika, 52, 591–611. 
Shen, Y., Yun, H., Lipton, Z. C., Kronrod, Y., & Anandkumar, A. (2017). Deep active 
learning for named entity recognition. In Proceedings of the 2nd workshop on 
representation learning for NLP (pp. 252–256). 
Tabassum, J., Maddela, M., Xu, W., & Ritter, A. (2020). Code and named entity 
recognition in StackOverflow. In Proceedings of the 58th annual meeting of the 
association for computational linguistics (pp. 4913–4926). Online: Association for 
Computational Linguistics.  
Thanh-Nhan, H. L., Nguyen, H. H., & Thai-Nghe, N. (2016). Methods for building course 
recommendation systems. In 2016 eighth International conference on knowledge and 
systems engineering (pp. 163–168). KSE).  
Tukey, J. W. (1949). Comparing individual means in the analysis of variance. Biometrics, 
5, 99–114. 
Valcarce, D., Bellogín, A., Parapar, J., & Castells, P. (2020). Assessing ranking metrics in 
top-N recommendation. Information Retrieval Journal, 23, 411–448. 
Valstar, S. (2019). Closing the academia-industry gap in undergraduate CS. In Proceedings 
of the 2019 ACM conference on International computing education research (pp. 
357–358). New York, NY, USA: Association for Computing Machinery.  
Voorhees, E. M., Harman, D. K., et al. (2005). TREC: Experiment and evaluation in 
information retrieval (Vol 63). MA: MIT Press Cambridge.  
Wang, C., Chen, W., & Xu, B. (2017). Named entity recognition with gated convolutional 
neural networks. In M. Sun, X. Wang, B. Chang, & D. Xiong (Eds.), Chinese 
computational linguistics and natural language processing based on naturally annotated 
big data (pp. 110–121). Cham: Springer International Publishing.  
Xiao, J., Wang, M., Jiang, B., & Li, J. (2018). A personalized recommendation system 
with combinational algorithm for online learning. Journal of Ambient Intelligence and 
Humanized Computing, 9, 667–677. 
Ye, D., Xing, Z., Foo, C. Y., Ang, Z. Q., Li, J., & Kapre, N. (2016). Software-specific named 
entity recognition in software engineering social content. In 2016 IEEE 23rd 
International conference on software analysis, evolution, and reengineering (SANER) (pp. 
90–101). 
Zhang, Q., Fu, J., Liu, X., & Huang, X. (2018). Adaptive Co-attention network for named 
entity recognition in tweets. In Proceedings of the AAAI conference on artificial 
intelligence (Vol. 32). 
Zhou, C., Li, B., & Sun, X. (2020). Improving software bug-specific named entity 
recognition with deep neural network. Journal of Systems and Software, 165, 110572. 
Zhu, M. (2004). Recall, precision and average precision (Vol. 2, p. 6). Waterloo: Department 
of Statistics and Actuarial Science, University of Waterloo. N.N.Y. Vo et al.                                                                                                                                                                                                                                 

